---
title: "Thesis Reticulate Draft 2"
author: "Stella Veazey"
date: "10/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, python=reticulate::eng_python)
```

```{r}
setwd("~/Desktop/Projects/thesis")
library(reticulate)
source_python("GSfunction.py")
library(mvtnorm)
library(BBmisc)
library(MatchIt)
library(randomForest)
library(cem)
library(readr)
library(plyr)
library(dplyr)
library(Hmisc)
library(pROC)
library(parallel)
library(caret)
library(readr)
library(dplyr)
library(Hmisc)
library(MatchIt)
library(cem)
path_to_python <- "/usr/local/bin/python3" 
use_python(path_to_python)
```


```{python}
from __future__ import print_function
from numpy import random as nprand
import math
import numpy as np

import sys, os
print("which python")
print(os.path.dirname(sys.executable))

import pandas as pd
import random
from sklearn.metrics.pairwise import manhattan_distances, pairwise_distances
import time
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import SGDClassifier, LogisticRegression
from sklearn.neural_network import MLPClassifier, BernoulliRBM
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from scipy.stats import pearsonr
import itertools as it
from itertools import combinations
from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression
import pprint
from scipy.stats import mode
from sklearn.ensemble.forest import _partition_estimators, parallel_helper
from sklearn.tree._tree import DTYPE
from sklearn.externals.joblib import Parallel, delayed
from sklearn.utils import check_array
from sklearn.utils.validation import check_is_fitted
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from sklearn.linear_model import LogisticRegression
import multiprocessing as mp
import statistics
```

Generate data

```{r}
set.seed(107)
### generating data
sigma <- matrix(c(1, 0, 0, 0, .2, 0, 0, 0, 0, 0,
                  0, 1, 0, 0, 0, .9, 0, 0, 0, 0,
                  0, 0, 1, 0, 0, 0, 0, .2, 0, 0,
                  0, 0, 0, 1, 0, 0, 0, 0, .9, 0,
                  .2, 0, 0, 0, 1, 0, 0, 0, 0, 0,
                  0, .9, 0, 0, 0, 1, 0, 0, 0, 0,
                  0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
                  0, 0, .2, 0, 0, 0, 0, 1, 0, 0,
                  0, 0, 0, .9, 0, 0, 0, 0, 1, 0,
                  0, 0, 0, 0, 0, 0, 0, 0, 0, 1), 
                ncol=10)

sims <- function(sigma, n=10000, dichotomize = c(1, 3, 6, 8, 9)) {
  x <- rmvnorm(n=n, mean=rep(0, length=10), sigma=sigma)
  x <- as.data.frame(x)
  
  a0 <- -1.897
  a1 <- .8
  a2 <- -0.25
  a3 <- 0.6
  a4 <- -.4
  a5 <- -.8
  a6 <- -.5
  a7 <- .7
  
  b0 <- -1.386
  b1 <- .3
  b2 <- -.36
  b3 <- -.73
  b4 <- -.2
  b5 <- .71
  b6 <- -.19
  b7 <- .26
  
  gamma <- -.4
  
  # true propensity score
  # scenario A: additivity and linearity
  x$lPRz <- a0 + a1*x[, 1] + a2*x[, 2] + a3*x[, 3] + a4*x[, 4] + a5*x[, 5] + a6*x[, 6] + a7*x[, 7]
  # convert to probability
  x$PRz <- exp(x$lPRz)/(1+exp(x$lPRz))
  x$PRz <- 1/(1 + exp(-(a0 + a1*x[, 1] + a2*x[, 2] + a3*x[, 3] + a4*x[, 4] + a5*x[, 5] + a6*x[, 6] + a7*x[, 7])))
  
  
  # assign treatment based on probability
  x$trt1 <- rep(NA, length(x$PRz))
  for (i in 1:length(x$PRz)) {
    u <- runif(n=1, min=0, max=1)
    x$trt1[i] <- ifelse(x$PRz[i] >= u, 1, 0)
  }
  # for (i in 1:length(x$PRz)) {
  #   x$trt1[i] <- rbinom(1, 1, prob=x$PRz[i])
  # }
   #x$trt1 <- round(x$PRz)
  
  
  # true outcomes
  # scenario A: additivity and linearity
  x$error <- rnorm(n, 0, .1)
  x$y1 <- b0 + b1*x[, 1] + b2*x[, 2] + b3*x[, 3] + b4*x[, 4] + b5*x[, 8] + b6*x[, 9] + b7*x[, 10] + gamma*x$trt1 + x$error
  
  if (!is.null(dichotomize)){
    for (i in dichotomize) {
      x[, i] <- ifelse(x[,i] > sample(x[,i], 1), 1, 0)
    }
  }
  df <- as.data.frame(cbind(x$y1, x[,1:10], x$trt1, x$PRz))
  names(df)[1] <- "y1"
  #names(df)[12] <- "trtRound"
  names(df)[12] <- "trt1"
  names(df)[13] <- "ps"

  return(df)
}

# No dichotomized
df1 <- as.data.frame(sims(sigma, n=10000, dichotomize = NULL))
write.csv(df1, "sim0.csv")
#prop.table(table(df1$trtRound))
prop.table(table(df1$trt1))

# One categoircal
set.seed(67)
df2 <- as.data.frame(sims(sigma, dichotomize = c(1,3)))
write.csv(df2, "sim2.csv")

```


Models


```{r}
# normalize X
newX <- normalize(df1[,2:11], method = "range", range = c(0, 1), margin = 2, on.constant = "quiet")
df1 <- as.data.frame(cbind(df1[,1], newX, df1[,12]))
names(df1) <- c("y1", "x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "trt1")



# train/test split
#names(df1)[2:11] <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8','x9', 'x10')
nx <- sample(nrow(df1), nrow(df1)/3)
dftrain1 <- df1[-nx,]
dftrain1 <- as.data.frame(dftrain1)
dftest1 <- df1[nx,]
row.names(dftest1) <- as.numeric(c(1:nrow(dftest1)))

## PS model
# Random Forest
# propensityIndex <- c(2:8) # because column 1 = y1
# psm1 <- randomForest(x= as.matrix(dftrain1[,propensityIndex]), y=as.factor(dftrain1$trt1))
# psmPred <- predict(psm1, as.matrix(dftest1[,propensityIndex]))
# roc(dftest1$trt1, as.numeric(psmPred))


X_train <- as.data.frame(dftrain1[,2:11])
y_train <- dftrain1[,1]
trt_train <- dftrain1[,12]
X_test <- dftest1[,2:11]
y_test <- dftest1[,1]
trt_test <- dftest1[,12]


#LR
psm1 <- glm(factor(trt1) ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data=dftrain1, family=binomial)
logitPred <- predict(psm1, dftest1, type="response")
roc(response = dftest1$trt1, predictor = logitPred)
require(rms)
mod1b <- lrm(factor(trt1) ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data=df1)
print(mod1b)


mean(logitPred)

## Outcome model
# treated
dftrainTrt1 <- dftrain1[dftrain1$trt1==1,]
dftrainCtrl1 <- dftrain1[dftrain1$trt1==0,]
dftestTrt1 <- dftest1[dftest1$trt1==1,]
dftestCtrl1 <- dftest1[dftest1$trt1==0,]

rfTrt <- randomForest(y1 ~ x1 + x2 + x3 + x4 + x8 + x9 + x10, data=dftrainTrt1)
rfTrtPred <- predict(rfTrt, dftestTrt1)
cor(rfTrtPred, dftestTrt1$y1)^2

outcomeTrt <- function(x){
  x <- matrix(x, ncol=10, nrow=1)
  x <- as.data.frame(x)
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  out <- predict(rfTrt, x)
  return(out)
}

# control
rfCtrl <- randomForest(y1 ~ x1 + x2 + x3 + x4 + x8 + x9 + x10, data=dftrainCtrl1)
rfCtrlPred <- predict(rfCtrl, dftestCtrl1)
cor(rfCtrlPred, dftestCtrl1$y1)^2

outcomeCtrl <- function(x){
  x <- matrix(x, ncol=10, nrow=1)
  x <- as.data.frame(x)
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  out <- predict(rfCtrl, x)
  return(out)
}
```

Wrapper functions and selecting observation to analyze

```{r}
# arguments
predCtrl <- function(x){
  predict(rfCtrl, x)
}

predTrt <- function(x){
  predict(rfTrt, x)
}


# for logistic PS only!
predPsm <- function(x){
  x <- as.data.frame(x)
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  ps <- predict(psm1, x, type="response")
  ps1 <- round(ps)
  return(ps1)
}

predPS <- function(x){
  x <- as.data.frame(x)
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  ps <- predict(psm1, x, type="response")
  return(ps)
}

index <- sample(nrow(dftest1), 1)
obs <- dftest1[index,]

propensityIndex=c(0:6)
outcomeIndex=c(0:3, 7:9)
```


Arguments

```{r}
observation=matrix(obs)
X=X_test
y=y_test
treat=trt_test
propensityIndex=matrix(propensityIndex, nrow=1, ncol=length(propensityIndex))
propensityIndex
outcomeIndex=matrix(outcomeIndex, nrow=1, ncol=length(outcomeIndex))
outcomeIndex
outcomeTrt=predTrt
outcomeCtrl=predCtrl
idx=as.integer(index)
score_function=predPS
cat=c(1, 3)
```

Trying to figure out if loop is repeating infinitely

```{python}
X=r.X
outcomeIndex=r.outcomeIndex
outcomeIndex=outcomeIndex[0]
propensityIndex=r.propensityIndex[0]
observation=np.asarray(r.observation)
treat=r.trt_test
center=observation
d=X.shape[1]
step=1/100
dfe, fe = distance_first_ennemy2(X=X, observation=observation, propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, score_function=r.score_function, treat=r.trt_test, idx=r.index, n=1, cat=None)
step = dfe * step
a0, a1 = 0, step
segment=(a0, a1)
n_layer=10000
n=n_layer
obs_to_interprete=observation
score_function=r.score_function
catidx=None
p=None
score_function_CLASS = treat[r.idx]
dfe
fe
```


```{python}
# a0 += step
# a1 += step
# segment=(a0, a1)
# segment
# obs_to_interprete
# layer_ = generate_layer_with_score_function(X, score_function, obs_to_interprete, d=X.shape[1], n=n_layer, segment=(a0, a1), propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, catidx=catidx, catdat=p)
# print(layer_[1])
# layer_enn = [x for x in layer_ if x[-1] == 1-score_function_CLASS]
# meanz = pd.DataFrame(layer_).mean()
# sdz = pd.DataFrame(layer_).var()
# len(layer_enn)
# # print('seg', seg)
# # statistics.mean(layer_[:,-1])
# # print('a0', a0)
# # print('a1', a1)
# # print('segment', segment)
# meanz
```


```{r}
# layer <- py$layer_
# layer <- layer[[1]]
# layer <- as.data.frame(layer)
# names(layer) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'pps')
# layer$ps <- predict(psm1, layer, type="response")
# # meanz[[b]] <- c(py$meanz)
# # 
# # score_function(matrix(meanz[[b]][1:10], ncol=10))
# # b=b+1
```

```{python}
# a0 += step
# a1 += step
# print(a0, a1)
```


```{python}
X=r.X
#type(X)
#print(X)
outcomeIndex=r.outcomeIndex
outcomeIndex=outcomeIndex[0]
print(outcomeIndex)
#type(outcomeIndex)
observation=np.asarray(r.observation)
observation=observation
#type(observation)
treat=r.trt_test

```


```{python}
X=r.X
#type(X)
#print(X)
outcomeIndex=r.outcomeIndex
outcomeIndex=outcomeIndex[0]
propensityIndex=r.propensityIndex[0]
#type(outcomeIndex)
observation=np.asarray(r.observation)
type(observation)
len(observation)
outcomeIndex=r.outcomeIndex
outcomeIndex=outcomeIndex[0]

# n=1000
# d=X.shape[1]
# step=1/10000000
# dfe, fe = distance_first_ennemy2(X=X, observation=observation, propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, score_function=r.score_function, treat=r.trt_test, idx=r.idx, n=1, cat=None)
# step = dfe * step
# a0 = 0
# a1 = step
# segment=(a0, a1)
# center=observation
# catidx=None



#cf, trt = gs(observation=observation[1:11], X=X, y=r.y_test, treat=r.trt_test, propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, outcomeTrt=r.outcomeTrt, outcomeCtrl=r.predCtrl, idx=r.idx, score_function=r.score_function, cat=None)
#start_time = time.time()
# def gs1(observation, index):
#     gs_main(X=X, y=r.y_test, treat=r.trt_test, score_function=r.score_function, obs_to_interprete=observation[1:11], propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, cat=None, idx=index)
# #print("--- %s seconds ---" % (time.time() - start_time))


def gsAll(x):
    obs1 = np.asarray(tuple((r.dftest1).iloc[int(x),:]))
    obs1 = obs1[1:11]
    obs1a = np.asarray(obs1).reshape(1, -1)
    obs1a = obs1a[0]
    print("pre main")
    main = gs_main(X=r.X_test, y=r.y_test, treat=r.trt_test, score_function=r.predPS, obs_to_interprete=obs1a, propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, cat=None, idx=int(x))
    return main
    
    





#gsAll2(2)

print("treat:", t)
print("x:", x)

df = np.asarray(tuple((r.dftest1)))

def test(x, trt):
    t=trt[x]
    return(t, x)
    
    
gsAll2(0)

    
# x=indices[1]
# obs1 = np.asarray(tuple((r.dftest1).iloc[indices[1],:]))
# obs1 = obs1[1:11]
# obs1a = np.asarray(obs1).reshape(1, -1)
# obs1a = obs1a[0]
# #main = gs_main(X=r.X_test, y=r.y_test, treat=r.trt_test, score_function=r.score_function, obs_to_interprete=obs1a, propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, cat=None, idx=int(x))
# 
# x = 2531
# obs1 = np.asarray(tuple((r.dftest1).iloc[int(x),:]))
# obs1
# obs1 = obs1[1:11]
# obs1.shape
# obs1a = np.asarray(obs1).reshape(1, -1)
# obs1a.shape
# obs1a = obs1a[0]
# obs1a




#main = gs_main(X=r.X_test, y=r.y_test, treat=r.trt_test, score_function=r.score_function, obs_to_interprete=obs1a, propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, cat=None, idx=int(x))
#print("main:", main)
# observation=np.asarray(tuple(observation))[0]
# observation
# observation[outcomeIndex]
# D = pairwise_distances(X.iloc[:,outcomeIndex], pd.DataFrame(observation[outcomeIndex]).values.reshape(1, -1), metric='euclidean')
#D[D==0]=None
#idxes = sorted(enumerate(D), key=lambda x:x[1])
# out = []
# dists = []
k = 0
# while len(out) < 1 and k < len(idxes):
#i = idxes
# score_function(X.iloc[i[k][0], :].values.reshape(1, -1))
# if round(score_function(X.iloc[i[k][0], :].values.reshape(1, -1))) != treat[idx]:
#     out.append(X.iloc[i[k][0],:])
#     dists.append(pairwise_distances(X.iloc[i[k][0],outcomeIndex].values.reshape(1, -1), pd.DataFrame(observation[outcomeIndex]).values.reshape(1, -1))[0][0])


# x = int(4)
# obs1 = np.asarray(tuple(r.dftest1.iloc[x,:]))
# obs1 = obs1[1:11]
# obs1a = np.asarray(obs1).reshape(1, -1)
# print(obs1a[0])
# print(observation)
#observation=obs1a
```



```{python}

# def gsAll(x):
obs1 = np.asarray(tuple((r.dftest1).iloc[int(3),:]))
obs1 = obs1[1:11]
obs1a = np.asarray(obs1).reshape(1, -1)
obs1a = obs1a[0]
#     print("pre main")
#     main = gs_main(X=r.X_test, y=r.y_test, treat=r.trt_test, score_function=r.score_function, obs_to_interprete=obs1a, propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, cat=None, idx=int(x))
#     return(main)

obs1a[r.outcomeIndex]

```



```{python}
X=r.X_test
y=r.y_test
treat=r.trt_test
score_function=r.score_function
observation=np.asarray(r.observation)
obs_to_interprete=np.asarray(observation[1:11]).reshape(1, -1)
propensityIndex=r.propensityIndex[0]
propensityIndex=r.propensityIndex[0]
outcomeIndex=r.outcomeIndex[0]
idx=r.idx

obs1 = r.dftest1.iloc[4,:]
print(obs1)
obs2 = obs1[1:11]
obs2 = np.asarray(obs2).reshape(1, -1)
print(obs2)
type(obs2)

obs_to_interprete=obs2


# def gs1(observation, index):
#     observation = np.asarray(observation)
#     print(observation[1:11])
#     index = np.asarray(index)
#     return(gs_main(X=X, y=r.y_test, treat=r.trt_test, score_function=r.score_function, obs_to_interprete=observation[1:11], propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, cat=None, idx=r.idx))
# #print("--- %s seconds ---" % (time.time() - start_time))


```


```{python}

def myFn1(x):
    return(sqrt(x))


```

```{r}

numCores <- detectCores()

#pbmcapply - mclapply wrapper

# cl <- makeCluster(detectCores(), type='PSOCK')
# registerDoParallel(cl)
# llply(list(2, 3, 4), .fun=py$myFn1, .parallel=TRUE)
# stopCluster(cl)

indices <- sample(seq(nrow(dftest1)), 25)
indices[1]
dftest1[indices[1]+1,]
predPS(as.matrix(dftest1[indices[1]+1,2:11], ncol=10, nrow=1))
adv <- list()
advEnn <- list()
og <- list()
sysTime <- list()
# for (i in 1:2){
#   sysTime[[i]] <- system.time(adv[[i]] <- py$gsAll(indices[i]))
#   og[[i]] <- dftest1[indices[i]+1, ]
#   print(i)
#   print(sysTime)
# }

# py$gsAll(indices[1])
# 
# sysTime[[1]] <- system.time(adv[[1]] <- py$gsAll(indices[1]))
# sysTime[[1]]
# og[[1]] <- dftest1[indices[1]+1, ]
# sysTime[[2]] <- system.time(adv[[2]] <- py$gsAll(indices[2]))
# sysTime[[2]]
# og[[2]] <- dftest1[indices[2]+1, ]
# sysTime[[3]] <- system.time(adv[[3]] <- py$gsAll(indices[3]))
# sysTime[[3]]
# og[[3]] <- dftest1[indices[3]+1, ]
# sysTime[[4]] <- system.time(adv[[4]] <- py$gsAll(indices[4]))
# sysTime[[4]]
# og[[4]] <- dftest1[indices[4]+1, ]
# sysTime[[5]] <- system.time(adv[[5]] <- py$gsAll(indices[5]))
# sysTime[[5]]
# og[[5]] <- dftest1[indices[5]+1, ]
# sysTime[[6]] <- system.time(adv[[6]] <- py$gsAll(indices[6]))
# sysTime[[6]]
# og[[6]] <- dftest1[indices[6]+1, ]
# 
# sysTime[[7]] <- system.time(adv[[7]] <- py$gsAll(indices[7]))


# system.time({
# for (i in 1:25) {
#   sysTime[[i]] <- system.time({
#     adv[[i]] <- py$gsAll(indices[i])
#   })
#   og[[i]] <- dftest1[indices[i]+1, ]
#   print(i)
#   print(sysTime[[i]])
# }})

library(pbmcapply)
system.time(
  results <- pbmclapply(c(indices[1:25]), py$gsAll, mc.cores = 8)
)
og = list()
for (i in 1:length(indices)){
  og[[i]] <- dftest1[indices[i]+1, ]
}


#system.time({advs <- llply(c(seq(1, 16)), .fun = py$gsAll, .progress="text")})


# 
# 
# registerDoParallel(cl)
# system.time({advs <- mclapply(1:10, .fun = py$gsAll, .parallel=TRUE)})

```



```{r}
# advs2 <- list()
# for (i in 1:length(adv)) {
#   if (length(adv[[i]][[1]]) > 1) {
#     z <- llply(adv[[i]][[1]], function(x) {
#       dist(rbind(x[-11], og[[i]][2:11]))
#     })
#     j <- which(as.vector(z, mode="numeric") == min(as.vector(z, mode="numeric")))
#     advs2[[i]] <- adv[[i]][[1]][j] }
#   else {advs2[[i]] <- adv[[i]]}
# }



outcomeTrt <- function(x){
  x <- as.data.frame(as.matrix(x, ncol=10, nrow=1))
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  out <- predict(rfTrt, x)
  return(out)}

outcomeCtrl <- function(x){
  x <- as.data.frame(as.matrix(x, ncol=10, nrow=1))
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  out <- predict(rfCtrl, x)
  return(out)}
  
adv = results
advPS <- llply(adv, function(x) {
  predPS(matrix(unlist(x[[1]])[1:10], ncol=10, nrow=1))
})

advTrtOutcome <- lapply(adv, function(x) {
  outcomeTrt(matrix(unlist(x[[1]])[1:10], ncol=10, nrow=1))
})

ogTrtOutcome <- lapply(og, function(x) {
  outcomeTrt(matrix(unlist(x)[1:10], ncol=10, nrow=1))
})

advCtrlOutcome <- lapply(adv, function(x) {
  outcomeCtrl(matrix(unlist(x[[1]])[1:10], ncol=10, nrow=1))
})

ogCtrlOutcome <- lapply(og, function(x) {
  outcomeCtrl(matrix(unlist(x)[1:10], ncol=10, nrow=1))
})

ogOutcome <- lapply(og, function(x) {
  x[1] })

ite <- list()
bias <- list()
for (i in 1:length(og)) {
  if (og[[i]][12] == 0) {
    ite[[i]] <- advTrtOutcome[[i]] - ogOutcome[[i]]
    bias[[i]] <- ite[[i]] + .4
  } else {
    ite[[i]] <- ogOutcome[[i]] - advCtrlOutcome[[i]]
    bias[[i]] <- ite[[i]] + .4
  }}

mean(unlist(ite))
sd(unlist(ite))
mean(unlist(bias))
sd(unlist(bias))


# write.csv(adv, file="adv")
# write.csv(og, file="og")

```

Model ITE

```{r}
modelITE <- list()
modelBias <- list()
for (i in 1:length(og)) {
  if (og[[i]][12] == 0) {
    modelITE[[i]] <- ogTrtOutcome[[i]] - ogOutcome[[i]]
    modelBias[[i]] <- modelITE[[i]] + .4
  } else {
    modelITE[[i]] <- ogOutcome[[i]] - ogCtrlOutcome[[i]]
    modelBias[[i]] <- modelITE[[i]] + .4
  }}

mean(unlist(modelITE))
sd(unlist(modelITE))
mean(unlist(modelBias))
sd(unlist(modelBias))

gsITE <- cbind(advPS, advTrtOutcome, ogTrtOutcome, advCtrlOutcome, ogCtrlOutcome, ogTrtOutcome, ogOutcome, ite, bias, modelITE, modelBias)
# write.csv(gsITE, file="gsITE")
```



Matching

```{r}
##############
### No cat ###
##############

formula.matching <- as.formula("trt1 ~ x1 + x2 + x3 + x4 + x5 + x6 + x7")
psdat <- df1[,-c(1, 9:11)]
m.out.cem <- matchit(as.factor(trt1) ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data = psdat, method = "cem")
# 
cem1 <- cem(treatment = "trt1", data=psdat)
z <- pair(cem1, data=psdat)
m.data.cem <- match.data(m.out.cem)
# 
indices <- indices + 1
# 
dataCEMidx <- m.data.cem[indices,]
# 
# # get matched indexes
# h <- rep(NA, length(indices))
# for (i in 1:length(indices)) {
#   h[i] <- z[["full.paired"]][[indices[i]]]
# }
# 
# ite <- rep(NA, 25)
FullData <- psdat
# for (i in 1:length(indices)){
#   if (FullData[i, 11] == 1) {
#     ite[i] <- FullData[i, 12] - FullData[z[["full.paired"]][[indices[i]]], 12] }
#   else {
#     ite[i] <- FullData[z[["full.paired"]][[indices[i]]], 12]-FullData[i, 12]
#   }}
# summary(as.numeric(ite))
# 
# cemBias <- as.numeric(ite)+.4
# describe(cemBias)


# Nearest neighbor matching
m.out.nn <- matchit(trt1~x1 + x2 + x3 + x4 + x5 + x6 + x7, data=dftest1[,-c(1, 9:11)], method="nearest", replace=TRUE)
nnmx <- m.out.nn$match.matrix
nnDta <- match.data(m.out.nn)

iteNN <- rep(NA, length(indices))
nnBias <- rep(NA, length(indices))
for (i in 1:length(indices)){
  if (dftest1[i, 12] == 1) {
    iteNN[i] <- dftest1[i, 1] - dftest1[nnmx[i,], 1] 
    nnBias[i] <- as.numeric(iteNN[i]) + .4 }
  else {
    iteNN[i] <- dftest1[nnmx[i,], 1]-dftest1[i, 1]
    nnBias[i] <- as.numeric(iteNN[i]) + .4
  }}


summary(as.numeric(iteNN))
mean(nnBias)
sd(nnBias)

nnITE <- cbind(iteNN, nnBias)
write.csv(nnITE, "nnITE.csv")
write.csv(nnDta, "nnDta.csv")
write.csv(nnmx, "nnmx.csv")


# estTrt <- function(original, counterfactual) {
#   if (original$trt == 1) {
#     y.trt = original$y
#     y.ctrl <- b0 + b1*counterfactual[, 1] + b2*counterfactual[, 2] + b3*counterfactual[, 3] + b4*counterfactual[, 4] + b5*counterfactual[, 8] + b6*counterfactual[, 9] + b7*counterfactual[, 10] + counterfactual[,11]
#   }
#   else {
#     y.trt <- b0 + b1*original[, 1] + b2*original[, 2] + b3*original[, 3] + b4*original[, 4] + b5*original[, 8] + b6*original[, 9] + b7*original[, 10] + gamma + original[,11]
#     y.ctrl=counterfactual$y 
#   }
#   y.trt-y.ctrl
# }
# 
# estTrt(orig, counterfactual)
# 
# i<-orig # y_treatment=-1.963324; ctrl = -1.563324 (-0.4)
# -1.963324 + 1.563324
# i=match # y=-1.738147
# -1.963324 + 1.738147
# 
# # treated
# y.orig <- b0 + b1*i[, 1] + b2*i[, 2] + b3*i[, 3] + b4*i[, 4] + b5*i[, 8] + b6*i[, 9] + b7*i[, 10] + gamma*i$trt+ i[,11]
# 
# # countrol
# y.orig <- b0 + b1*i[, 1] + b2*i[, 2] + b3*i[, 3] + b4*i[, 4] + b5*i[, 8] + b6*i[, 9] + b7*i[, 10] + i[,11]

```

plot

```{r}
nnITE2 <- as.data.frame(nnITE, ncol=2)
names(nnITE2) <- c("ITE", "bias")
nnITE2$method <- rep("NN", nrow(nnITE2))

tcITE <- as.data.frame(cbind(modelITE, modelBias), ncol=2)
names(tcITE) <- c("ITE", "bias")
tcITE$method <- rep("RF", nrow(tcITE))

gsITE <- as.data.frame(cbind(ite, bias), ncol=2)
names(gsITE) <- c("ITE", "bias")
gsITE$method <- rep("GS", nrow(gsITE))

iteOverall <- as.data.frame(rbind(nnITE2, tcITE, gsITE))

write.csv(iteOverall, "iteOverall.csv")
```

