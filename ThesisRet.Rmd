---
title: "Thesis Reticulate Draft 2"
author: "Stella Veazey"
date: "10/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, python=reticulate::eng_python)
```

```{r}
setwd("~/Desktop/Projects/thesis")
library(reticulate)
source_python("GSfunction.py")
library(mvtnorm)
library(BBmisc)
library(MatchIt)
library(randomForest)
library(cem)
library(readr)
library(plyr)
library(dplyr)
library(Hmisc)
library(pROC)
library(parallel)
library(caret)
library(readr)
library(dplyr)
library(Hmisc)
library(MatchIt)
library(cem)
path_to_python <- "/usr/local/bin/python3" 
use_python(path_to_python)
```


```{python}
from __future__ import print_function
from numpy import random as nprand
import math
import numpy as np

import sys, os
print("which python")
print(os.path.dirname(sys.executable))

import pandas as pd
import random
from sklearn.metrics.pairwise import manhattan_distances, pairwise_distances
import time
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import SGDClassifier, LogisticRegression
from sklearn.neural_network import MLPClassifier, BernoulliRBM
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from scipy.stats import pearsonr
import itertools as it
from itertools import combinations
from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression
import pprint
from scipy.stats import mode
from sklearn.ensemble.forest import _partition_estimators, parallel_helper
from sklearn.tree._tree import DTYPE
from sklearn.externals.joblib import Parallel, delayed
from sklearn.utils import check_array
from sklearn.utils.validation import check_is_fitted
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from sklearn.linear_model import LogisticRegression
import multiprocessing as mp
import statistics
```

Generate data

```{r}
set.seed(107)
### generating data
sigma <- matrix(c(1, 0, 0, 0, .2, 0, 0, 0, 0, 0,
                  0, 1, 0, 0, 0, .9, 0, 0, 0, 0,
                  0, 0, 1, 0, 0, 0, 0, .2, 0, 0,
                  0, 0, 0, 1, 0, 0, 0, 0, .9, 0,
                  .2, 0, 0, 0, 1, 0, 0, 0, 0, 0,
                  0, .9, 0, 0, 0, 1, 0, 0, 0, 0,
                  0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
                  0, 0, .2, 0, 0, 0, 0, 1, 0, 0,
                  0, 0, 0, .9, 0, 0, 0, 0, 1, 0,
                  0, 0, 0, 0, 0, 0, 0, 0, 0, 1), 
                ncol=10)

sims <- function(sigma, n=10000, dichotomize = c(1, 3, 6, 8, 9)) {
  x <- rmvnorm(n=n, mean=rep(0, length=10), sigma=sigma)
  x <- as.data.frame(x)
  
  a0 <- -1.897
  a1 <- .8
  a2 <- -0.25
  a3 <- 0.6
  a4 <- -.4
  a5 <- -.8
  a6 <- -.5
  a7 <- .7
  
  b0 <- -1.386
  b1 <- .3
  b2 <- -.36
  b3 <- -.73
  b4 <- -.2
  b5 <- .71
  b6 <- -.19
  b7 <- .26
  
  gamma <- -.4
  
  # true propensity score
  # scenario A: additivity and linearity
  x$lPRz <- a0 + a1*x[, 1] + a2*x[, 2] + a3*x[, 3] + a4*x[, 4] + a5*x[, 5] + a6*x[, 6] + a7*x[, 7]
  # convert to probability
  x$PRz <- exp(x$lPRz)/(1+exp(x$lPRz))
  x$PRz <- 1/(1 + exp(-(a0 + a1*x[, 1] + a2*x[, 2] + a3*x[, 3] + a4*x[, 4] + a5*x[, 5] + a6*x[, 6] + a7*x[, 7])))
  
  
  # assign treatment based on probability
  x$trt1 <- rep(NA, length(x$PRz))
  for (i in 1:length(x$PRz)) {
    u <- runif(n=1, min=0, max=1)
    x$trt1[i] <- ifelse(x$PRz[i] >= u, 1, 0)
  }
  # for (i in 1:length(x$PRz)) {
  #   x$trt1[i] <- rbinom(1, 1, prob=x$PRz[i])
  # }
   #x$trt1 <- round(x$PRz)
  
  
  # true outcomes
  # scenario A: additivity and linearity
  x$error <- rnorm(n, 0, .1)
  x$y1 <- b0 + b1*x[, 1] + b2*x[, 2] + b3*x[, 3] + b4*x[, 4] + b5*x[, 8] + b6*x[, 9] + b7*x[, 10] + gamma*x$trt1 + x$error
  
  if (!is.null(dichotomize)){
    for (i in dichotomize) {
      x[, i] <- ifelse(x[,i] > sample(x[,i], 1), 1, 0)
    }
  }
  df <- as.data.frame(cbind(x$y1, x[,1:10], x$trt1, x$PRz))
  names(df)[1] <- "y1"
  #names(df)[12] <- "trtRound"
  names(df)[12] <- "trt1"
  names(df)[13] <- "ps"

  return(df)
}

# No dichotomized
df1 <- as.data.frame(sims(sigma, n=10000, dichotomize = NULL))
write.csv(df1, "sim0.csv")
#prop.table(table(df1$trtRound))
prop.table(table(df1$trt1))

# One categoircal
set.seed(67)
df2 <- as.data.frame(sims(sigma, dichotomize = c(1,3)))
write.csv(df2, "sim2.csv")

```


Models


```{r}
# normalize X
newX <- normalize(df1[,2:11], method = "range", range = c(0, 1), margin = 2, on.constant = "quiet")
df1 <- as.data.frame(cbind(df1[,1], newX, df1[,12]))
names(df1) <- c("y1", "x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "trt1")



# train/test split
#names(df1)[2:11] <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8','x9', 'x10')
nx <- sample(nrow(df1), nrow(df1)/3)
dftrain1 <- df1[-nx,]
dftrain1 <- as.data.frame(dftrain1)
dftest1 <- df1[nx,]
row.names(dftest1) <- as.numeric(c(1:nrow(dftest1)))

## PS model
# Random Forest
# propensityIndex <- c(2:8) # because column 1 = y1
# psm1 <- randomForest(x= as.matrix(dftrain1[,propensityIndex]), y=as.factor(dftrain1$trt1))
# psmPred <- predict(psm1, as.matrix(dftest1[,propensityIndex]))
# roc(dftest1$trt1, as.numeric(psmPred))


X_train <- as.data.frame(dftrain1[,2:11])
y_train <- dftrain1[,1]
trt_train <- dftrain1[,12]
X_test <- dftest1[,2:11]
y_test <- dftest1[,1]
trt_test <- dftest1[,12]


#LR
psm1 <- glm(factor(trt1) ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data=dftrain1, family=binomial)
logitPred <- predict(psm1, dftest1, type="response")
roc(response = dftest1$trt1, predictor = logitPred)
require(rms)
mod1b <- lrm(factor(trt1) ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data=df1)
print(mod1b)


mean(logitPred)

## Outcome model
# treated
dftrainTrt1 <- dftrain1[dftrain1$trt1==1,]
dftrainCtrl1 <- dftrain1[dftrain1$trt1==0,]
dftestTrt1 <- dftest1[dftest1$trt1==1,]
dftestCtrl1 <- dftest1[dftest1$trt1==0,]

rfTrt <- randomForest(y1 ~ x1 + x2 + x3 + x4 + x8 + x9 + x10, data=dftrainTrt1)
rfTrtPred <- predict(rfTrt, dftestTrt1)
cor(rfTrtPred, dftestTrt1$y1)^2

outcomeTrt <- function(x){
  x <- matrix(x, ncol=10, nrow=1)
  x <- as.data.frame(x)
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  out <- predict(rfTrt, x)
  return(out)
}

# control
rfCtrl <- randomForest(y1 ~ x1 + x2 + x3 + x4 + x8 + x9 + x10, data=dftrainCtrl1)
rfCtrlPred <- predict(rfCtrl, dftestCtrl1)
cor(rfCtrlPred, dftestCtrl1$y1)^2

outcomeCtrl <- function(x){
  x <- matrix(x, ncol=10, nrow=1)
  x <- as.data.frame(x)
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  out <- predict(rfCtrl, x)
  return(out)
}
```

Wrapper functions and selecting observation to analyze

```{r}
# arguments
predCtrl <- function(x){
  predict(rfCtrl, x)
}

predTrt <- function(x){
  predict(rfTrt, x)
}


# for logistic PS only!
predPsm <- function(x){
  x <- as.data.frame(x)
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  ps <- predict(psm1, x, type="response")
  ps1 <- round(ps)
  return(ps1)
}

predPS <- function(x){
  x <- as.data.frame(x)
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  ps <- predict(psm1, x, type="response")
  return(ps)
}

index <- sample(nrow(dftest1), 1)
obs <- dftest1[index,]

propensityIndex=c(0:6)
outcomeIndex=c(0:3, 7:9)
```


Arguments

```{r}
observation=matrix(obs)
X=X_test
y=y_test
treat=trt_test
propensityIndex=matrix(propensityIndex, nrow=1, ncol=length(propensityIndex))
propensityIndex
outcomeIndex=matrix(outcomeIndex, nrow=1, ncol=length(outcomeIndex))
outcomeIndex
outcomeTrt=predTrt
outcomeCtrl=predCtrl
idx=as.integer(index)
score_function=predPS
cat=c(1, 3)
```


```{python}
X=r.X
#type(X)
#print(X)
outcomeIndex=r.outcomeIndex
outcomeIndex=outcomeIndex[0]
#type(outcomeIndex)
observation=np.asarray(r.observation)
observation=observation
#type(observation)
treat=r.trt_test
propensityIndex=r.propensityIndex[0]

```


```{python}

def gsAll(x):
    obs1 = np.asarray(tuple((r.dftest1).iloc[int(x),:]))
    obs1 = obs1[1:11]
    obs1a = np.asarray(obs1).reshape(1, -1)
    obs1a = obs1a[0]
    print("pre main")
    main = gs_main(X=r.X_test, y=r.y_test, treat=r.trt_test, score_function=r.predPS, obs_to_interprete=obs1a, propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, cat=None, idx=int(x))
    return main
    
    
```



```{python}

# def gsAll(x):
obs1 = np.asarray(tuple((r.dftest1).iloc[int(3),:]))
obs1 = obs1[1:11]
obs1a = np.asarray(obs1).reshape(1, -1)
obs1a = obs1a[0]
#     print("pre main")
#     main = gs_main(X=r.X_test, y=r.y_test, treat=r.trt_test, score_function=r.score_function, obs_to_interprete=obs1a, propensityIndex=propensityIndex, outcomeIndex=outcomeIndex, cat=None, idx=int(x))
#     return(main)

obs1a[r.outcomeIndex]

```



```{python}
X=r.X_test
y=r.y_test
treat=r.trt_test
score_function=r.score_function
observation=np.asarray(r.observation)
obs_to_interprete=np.asarray(observation[1:11]).reshape(1, -1)
propensityIndex=r.propensityIndex[0]
propensityIndex=r.propensityIndex[0]
outcomeIndex=r.outcomeIndex[0]
idx=r.idx

obs1 = r.dftest1.iloc[4,:]
print(obs1)
obs2 = obs1[1:11]
obs2 = np.asarray(obs2).reshape(1, -1)
print(obs2)
type(obs2)

obs_to_interprete=obs2


```


```{r}

numCores <- detectCores()


indices <- sample(seq(nrow(dftest1)), 25)
indices[1]
dftest1[indices[1]+1,]
predPS(as.matrix(dftest1[indices[1]+1,2:11], ncol=10, nrow=1))
adv <- list()
advEnn <- list()
og <- list()
sysTime <- list()


# system.time({
# for (i in 1:25) {
#   sysTime[[i]] <- system.time({
#     adv[[i]] <- py$gsAll(indices[i])
#   })
#   og[[i]] <- dftest1[indices[i]+1, ]
#   print(i)
#   print(sysTime[[i]])
# }})

library(pbmcapply)
system.time(
  results <- pbmclapply(c(indices[1:25]), py$gsAll, mc.cores = 8)
)
og = list()
for (i in 1:length(indices)){
  og[[i]] <- dftest1[indices[i]+1, ]
}



```



```{r}
# advs2 <- list()
# for (i in 1:length(adv)) {
#   if (length(adv[[i]][[1]]) > 1) {
#     z <- llply(adv[[i]][[1]], function(x) {
#       dist(rbind(x[-11], og[[i]][2:11]))
#     })
#     j <- which(as.vector(z, mode="numeric") == min(as.vector(z, mode="numeric")))
#     advs2[[i]] <- adv[[i]][[1]][j] }
#   else {advs2[[i]] <- adv[[i]]}
# }



outcomeTrt <- function(x){
  x <- as.data.frame(as.matrix(x, ncol=10, nrow=1))
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  out <- predict(rfTrt, x)
  return(out)}

outcomeCtrl <- function(x){
  x <- as.data.frame(as.matrix(x, ncol=10, nrow=1))
  names(x) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10')
  out <- predict(rfCtrl, x)
  return(out)}
  
adv = results
advPS <- llply(adv, function(x) {
  predPS(matrix(unlist(x[[1]])[1:10], ncol=10, nrow=1))
})

advTrtOutcome <- lapply(adv, function(x) {
  outcomeTrt(matrix(unlist(x[[1]])[1:10], ncol=10, nrow=1))
})

ogTrtOutcome <- lapply(og, function(x) {
  outcomeTrt(matrix(unlist(x)[1:10], ncol=10, nrow=1))
})

advCtrlOutcome <- lapply(adv, function(x) {
  outcomeCtrl(matrix(unlist(x[[1]])[1:10], ncol=10, nrow=1))
})

ogCtrlOutcome <- lapply(og, function(x) {
  outcomeCtrl(matrix(unlist(x)[1:10], ncol=10, nrow=1))
})

ogOutcome <- lapply(og, function(x) {
  x[1] })

ite <- list()
bias <- list()
for (i in 1:length(og)) {
  if (og[[i]][12] == 0) {
    ite[[i]] <- advTrtOutcome[[i]] - ogOutcome[[i]]
    bias[[i]] <- ite[[i]] + .4
  } else {
    ite[[i]] <- ogOutcome[[i]] - advCtrlOutcome[[i]]
    bias[[i]] <- ite[[i]] + .4
  }}

mean(unlist(ite))
sd(unlist(ite))
mean(unlist(bias))
sd(unlist(bias))


# write.csv(adv, file="adv")
# write.csv(og, file="og")

```

Model ITE

```{r}
modelITE <- list()
modelBias <- list()
for (i in 1:length(og)) {
  if (og[[i]][12] == 0) {
    modelITE[[i]] <- ogTrtOutcome[[i]] - ogOutcome[[i]]
    modelBias[[i]] <- modelITE[[i]] + .4
  } else {
    modelITE[[i]] <- ogOutcome[[i]] - ogCtrlOutcome[[i]]
    modelBias[[i]] <- modelITE[[i]] + .4
  }}

mean(unlist(modelITE))
sd(unlist(modelITE))
mean(unlist(modelBias))
sd(unlist(modelBias))

gsITE <- cbind(advPS, advTrtOutcome, ogTrtOutcome, advCtrlOutcome, ogCtrlOutcome, ogTrtOutcome, ogOutcome, ite, bias, modelITE, modelBias)
# write.csv(gsITE, file="gsITE")
```



Matching

```{r}
##############
### No cat ###
##############

formula.matching <- as.formula("trt1 ~ x1 + x2 + x3 + x4 + x5 + x6 + x7")
psdat <- df1[,-c(1, 9:11)]
m.out.cem <- matchit(as.factor(trt1) ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data = psdat, method = "cem")
# 
cem1 <- cem(treatment = "trt1", data=psdat)
z <- pair(cem1, data=psdat)
m.data.cem <- match.data(m.out.cem)
# 
indices <- indices + 1
# 
dataCEMidx <- m.data.cem[indices,]
# 
# # get matched indexes
# h <- rep(NA, length(indices))
# for (i in 1:length(indices)) {
#   h[i] <- z[["full.paired"]][[indices[i]]]
# }
# 
# ite <- rep(NA, 25)
FullData <- psdat
# for (i in 1:length(indices)){
#   if (FullData[i, 11] == 1) {
#     ite[i] <- FullData[i, 12] - FullData[z[["full.paired"]][[indices[i]]], 12] }
#   else {
#     ite[i] <- FullData[z[["full.paired"]][[indices[i]]], 12]-FullData[i, 12]
#   }}
# summary(as.numeric(ite))
# 
# cemBias <- as.numeric(ite)+.4
# describe(cemBias)


# Nearest neighbor matching
m.out.nn <- matchit(trt1~x1 + x2 + x3 + x4 + x5 + x6 + x7, data=dftest1[,-c(1, 9:11)], method="nearest", replace=TRUE)
nnmx <- m.out.nn$match.matrix
nnDta <- match.data(m.out.nn)

iteNN <- rep(NA, length(indices))
nnBias <- rep(NA, length(indices))
for (i in 1:length(indices)){
  if (dftest1[i, 12] == 1) {
    iteNN[i] <- dftest1[i, 1] - dftest1[nnmx[i,], 1] 
    nnBias[i] <- as.numeric(iteNN[i]) + .4 }
  else {
    iteNN[i] <- dftest1[nnmx[i,], 1]-dftest1[i, 1]
    nnBias[i] <- as.numeric(iteNN[i]) + .4
  }}


summary(as.numeric(iteNN))
mean(nnBias)
sd(nnBias)

nnITE <- cbind(iteNN, nnBias)
write.csv(nnITE, "nnITE.csv")
write.csv(nnDta, "nnDta.csv")
write.csv(nnmx, "nnmx.csv")


# estTrt <- function(original, counterfactual) {
#   if (original$trt == 1) {
#     y.trt = original$y
#     y.ctrl <- b0 + b1*counterfactual[, 1] + b2*counterfactual[, 2] + b3*counterfactual[, 3] + b4*counterfactual[, 4] + b5*counterfactual[, 8] + b6*counterfactual[, 9] + b7*counterfactual[, 10] + counterfactual[,11]
#   }
#   else {
#     y.trt <- b0 + b1*original[, 1] + b2*original[, 2] + b3*original[, 3] + b4*original[, 4] + b5*original[, 8] + b6*original[, 9] + b7*original[, 10] + gamma + original[,11]
#     y.ctrl=counterfactual$y 
#   }
#   y.trt-y.ctrl
# }
# 
# estTrt(orig, counterfactual)
# 
# i<-orig # y_treatment=-1.963324; ctrl = -1.563324 (-0.4)
# -1.963324 + 1.563324
# i=match # y=-1.738147
# -1.963324 + 1.738147
# 
# # treated
# y.orig <- b0 + b1*i[, 1] + b2*i[, 2] + b3*i[, 3] + b4*i[, 4] + b5*i[, 8] + b6*i[, 9] + b7*i[, 10] + gamma*i$trt+ i[,11]
# 
# # countrol
# y.orig <- b0 + b1*i[, 1] + b2*i[, 2] + b3*i[, 3] + b4*i[, 4] + b5*i[, 8] + b6*i[, 9] + b7*i[, 10] + i[,11]

```

plot

```{r}
nnITE2 <- as.data.frame(nnITE, ncol=2)
names(nnITE2) <- c("ITE", "bias")
nnITE2$method <- rep("NN", nrow(nnITE2))

tcITE <- as.data.frame(cbind(modelITE, modelBias), ncol=2)
names(tcITE) <- c("ITE", "bias")
tcITE$method <- rep("RF", nrow(tcITE))

gsITE <- as.data.frame(cbind(ite, bias), ncol=2)
names(gsITE) <- c("ITE", "bias")
gsITE$method <- rep("GS", nrow(gsITE))

iteOverall <- as.data.frame(rbind(nnITE2, tcITE, gsITE))

write.csv(iteOverall, "iteOverall.csv")
```

